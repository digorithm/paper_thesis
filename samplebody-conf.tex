\section{Introduction}

The industrial adoption of microservices has led to increasingly complex configuration schemes that are commonly fine-tuned by engineers manually. Ganek and Corbi (2003) discussed the need for autonomic computing to handle the complexity of managing software systems. They noted that managing complex systems has become too costly, prone to error, and labor-intensive, because people under such pressure make mistakes, increasing the potential of system outages with a concurrent impact on business \cite{ganek_dawning_2003}. This has driven many researchers to study self-adaptive systems over the years \cite{porter_rex:_2016, andrew_pavlo_self-driving_2017, salehie_self-adaptive_2009, ganapathi_predicting_2009, herbst_self-adaptive_2014, faniyi_architecting_2014}; however, the software industry still lacks practical tools to provide self-adaptation mechanisms to their systems. Thus, most of the configuring and tuning of the systems are performed manually, often in run-time, which is known to be a very time consuming and risky practice \cite{ganek_dawning_2003, using_prob_reasoning_automate_software_tuning, de_lemos_software_2013}.

% Move Paul Horn stuff to Related Work

In this work we present an accessible tool to support the development of self-adaptive systems. One of our main goals is to provide such support requiring minimal effort from the engineers. In return our tool uses ideas from system observability, machine learning, and control theory to automatically asses the system's environment, predict the impact of changes that could potentially improve the system, and automatically make these changes.

Our approach consists of providing an API to collect relevant systems' metrics and configurations that represent the state of the system in relation to time. Then we map Service Level Objectives (SLOs) to some of these metrics, feed these into a machine learning component that is concurrently re-learning the model while analyzing and predicting the workload and the optimal configurations. As a result it provides adaptation plans that can be both 1) automatically executed, allowing the system to have self-adaptive capabilities, and 2) interpretable, allowing engineers to know the impact of a change in the configuration space before it is deployed.

In summary, our main contributions are:

\begin{itemize}
  \item We provide a methodology to assist the development and evolution of self-adaptive systems, regardless of the presence of self-adaptability in the system's foundations. Such methodology is encapsulated in the tool described in this work.
  \item We show how to make the minimal necessary changes to the system, and how to model SLAs/SLOs and map them to the optimization objectives. These tasks being the development cost incurred by the engineers.
  \item We present a case study that shows how a software system's response time, throughput, and usage were improved by $A\%$, $B\%$, and $C\%$ respectively after integrating a self-adaptation mechanism.
\end{itemize}

The rest of this paper is structure as follows: in Section 2 we discuss some past research in the space of self-adaptive systems and provide fundamental background. In Section 3 we outline our approach, explaining the blend of ideas from different fields. In Section 4 we describe internal details and design decisions of our implementation. In Section 5 we present our case study followed by a discussion and future directions in Section 6. Finally, we conclude our findings with Section 7.

%
% here we reorganize these characteristics into the following terminology:

% \begin{itemize}
%   \item \textbf{Self-Awareness}: an autonomic system needs to know itself;
%   \item \textbf{Self-configuring}: an autonomic system must configure and reconfigure itself under varying and unpredictable conditions;
%   \item \textbf{Self-optimization}: an autonomic system never settles for the status quo, it always looks for ways to optimize its workings, it will anticipate the optimized resources needed to meet a user's information needs while keeping its complexity hidden;
%   \item \textbf{Self-healing}: An autonomic system must perform something akin to healing, it must be able to recover from routine and extraordinary events that might cause some parts to malfunction.
% \end{itemize}


% \begin{itemize}
%   \item Use of system observability to collect a sufficiently big time series dataset that represents the state of a system and its components in relation to time;
%   \item Use of Machine Learning applied to time series data to analyze and predict workload and optimal configuration in order to provide adaptation plans;
%   \item Use of Online Learning to provide constant relearning of the model to adapt to different scenarios and requirements;
%   \item Use of Service Level Objectives as a way to define the system's performance goals that will be used by the tool as optimization objectives;
%   \item Use of the concepts in control theory as the central component of this tool, in which it implements a variation of the well known and studies MAPE loop (Monitor, Analyze, Plan, Execute);
%   \item Abstraction of all the concepts above into a tool that can be integrated to compatible systems, including systems that were built without self-adaptation in mind. 
% \end{itemize}

% The rest of the paper is structure as following: 


% I can develop a bit more on this by using this survey's result: According to a recent
% IT resource survey by the Merit Project of Computer Associates International, 1867 respondents grouped the most common causes of outages into four areas of data center operations: systems, networks, database, and applications.
% Most frequently cited outages included:
%- For systems: operational error, user error, third-party software error, internally %developed software problem, inadequate change control, lack of automated processes
%- For networks: performance overload, peak load problems, insufficient bandwidth
%- For database: out of disk space, log file full, performance overload
%- For  applications:  application  error,  inadequate change control, operational %error, nonautomated application exceptions
% A nice point is that these are the problems we're still facing whenever we deal poorly with the complexity of the systems

% It would be nice also to cite IBM autonomic computing initiative

% IBM’s autonomic computing initiative has been outlined broadly. Paul Horn described this “grand challenge” and called for industry-wide collaboration toward developing autonomic computing systems that have characteristics as follows: ● To be autonomic  a system needs to “ know itself ”— and consist of components that also possess a sys- tem identity. ● An autonomic system must con fi gure and recon- fi gure itself under varying and unpredictable con- ditions. ● An autonomic system never settles for the status quo — it always looks for ways to optimize its work- ings. ● An autonomic system must perform something akin to healing — it must be able to recover from routine and extraordinary events that might cause some parts to malfunction. ● A virtual world is no less dangerous than the phys- ical one, so an autonomic computing system must be an expert in self-protection. ● An autonomic computing system knows its envi- ronment and the context surrounding its activity, and acts accordingly. ● An autonomic system cannot exist in a hermetic environment (and must adhere to open standards). ● Perhaps most critical for the user, an autonomic computing system will anticipate the optimized re- sources needed to meet a user ’ s information needs while keeping its complexity hidden.

\section{Related Work}

Between the years of 2007 and 2011, many techniques for forecasting workload and performance metrics have been realized \cite{gmach2007workload, towards_autonomic_allocation, bobroff2007dynamic, meng2010efficient, caron2011pattern}. These works did not focus on tools for applying machine learning to software systems, however, they provided techniques and methodologies for virtual machine allocation in data centers; They used techniques that overlap with our work, in special: time series analysis.

Herbst et al. contributed with a survey of state-of-the-art forecasting approaches based on time series analysis and a decision-based technique to select the best forecasting method based on user-specified objectives \cite{herbst_self-adaptive_2014}. Although they did not focus on self-adaptability of systems in a finer-grained fashion, they did provide useful techniques to reliably forecast workload and performance, which is an important component in our tool -- to enable self-adaptation in a system is to first understand the patterns in its context over time.

Andrew Pavlo et al in their work entitled \textit{Self-Driving Database Management Systems} presented Peloton, a database system designed for autonomous operation. Similar to one of our goals, one of their main goals was to decrease the need for manually-performed operations, though they focused solely on their DBMS implementation. They achieved this by classifying the workload trends, collecting monitoring data, and forecasting resource utilization, then training a model based on this data to predict the best optimization plan. These ideas are important in our work, however, the key difference is that instead of directly embedding these ideas in a specific system -- in this case a DBMS -- and requiring the autonomous components to be tightly coupled, we are embedding a subset of these ideas in a tool that can be integrated in any chosen software system. 

% Next: using_prob_reasoning_automate_software_tuning

% https://arxiv.org/pdf/1712.01208.pdf cite this paper here as an example of a new trend emerging in industry and academia: substituting heuristics in software with machine learning models, making the algorithms more data-aware.


\section{Approach}

\subsection{Control theory and self-adaptive systems}

\subsection{System's configuration as an optimization problem}

\subsection{Providing system adaptation with machine learning}

\subsection{Workload simulation}

\subsection{System instrumentation}

\subsection{Machine learning architecture}

\subsubsection{Features and models}

\subsubsection{Online training}

\subsubsection{Achieving self-adapation}

\section{Implementation}

\section{Evaluation}

To guide and evaluate our work, four research questions are used:

\begin{itemize}
  \item \textbf{RQ1:} Can self-adaptation by learned models lead to more stable, faster, and safer software systems, reducing the need to manually configure and tune?
  \item \textbf{RQ2:} How much instrumentation, SLO mapping, and configuration mapping is required to integrate the tool in a system?
  \item \textbf{RQ3:} How much performance overhead is incurred by using this tool?
  \item \textbf{RQ4:} What metrics and features have more impact on the tool's performance?
\end{itemize}


%\textcolor{red}{Why RQ2 is interesting: RQ2 is an interesting question because most related works are very complex to implement/integrate, requiring a huge amount of work, and what's worse: unfamiliar work, whereas if we show that our software became self-adaptive by only requiring these 3 \textbf{familiar} tasks... then it could mean that this tool is somewhat easy to integrate and it's practical}

\section{Discussion and future work}

\section{Conclusions}

%\end{document}  % This is where a 'short' article might terminate

\nocite{*}

\begin{acks}

\end{acks} 